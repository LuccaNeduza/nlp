{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ad7c4-ac8b-43e8-a5a8-c8b47996de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processamento de Linguagem Natural\n",
    "# Frank Alcantara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be346b2-468e-4bb3-ac59-daa0774ea4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das Bibliotecas\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib.colors import ListedColormap\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2270219b-c402-438b-8cac-877e48fb179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser do livro 'Wealth of the Nations - Adam Smith'\n",
    "page = requests.get(\"https://www.gutenberg.org/files/3300/3300-h/3300-h.htm\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "html = list(soup.children)[2]\n",
    "body = list(html.children)[3]\n",
    "p = list(body.children)[1]\n",
    "size = len(soup.find_all('p'))\n",
    "palavras = \" \"\n",
    "for i in range(size):\n",
    "    words = soup.find_all('p')[i].get_text()\n",
    "    palavras = palavras + words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f1a271-2ecb-401d-8d53-097d8c8a8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento do texto\n",
    "text = palavras.lower()  # Lowercase text\n",
    "text = re.sub(r\"<.*?>\", \" \", text)  # remove all html tags\n",
    "text = re.sub(r\"\\b[0-9]+\\b\\s*\", \"\", text)  # remove numbers\n",
    "text = \" \".join([w for w in text.split() if not w.isdigit()])  # remove digits\n",
    "# text = re.sub(r\"<a[^>]*>(.*?)</a>\", r\"\\1\", text)  # remove just tags\n",
    "text = re.sub(r\"https?://\\S+\", \"\", text)  # remove hiperlinks\n",
    "text = re.sub(f\"[{re.escape(punctuation)}]\", \"\", text)  # Remove punctuation\n",
    "text = \" \".join(text.split())  # Remove extra spaces, tabs, and new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf6a15-fa94-472e-b118-d5d53b482bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a frequência de cada palavra do texto\n",
    "counts = dict()\n",
    "words = text.split()\n",
    "for word in words:\n",
    "    if word in counts:\n",
    "        counts[word] += 1\n",
    "    else:\n",
    "        counts[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0d408-87fd-4aa4-b9ad-5a3c7a4d2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold-Mikolov\n",
    "dic = dict()\n",
    "for key, value in counts.items():\n",
    "    prob = 1 - ((10 ** -0.0005) / value) ** 0.5\n",
    "    threshold = 0.7\n",
    "    if prob < threshold:\n",
    "        dic[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aedd74a-ef50-4430-898a-fc9ce6a305ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto final\n",
    "texto = \"\"\n",
    "for chave in dic.keys():\n",
    "    texto = texto + chave + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9bbe9-2146-475f-bc98-17f51c809c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva arquivo\n",
    "file1 = open(\"arquivo.txt\", mode=\"a+\", encoding=\"utf-8\")\n",
    "file1.writelines(texto)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9ef99b-c6ed-4582-998f-4b68f75513d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria Corpus\n",
    "dir = r\"C:\\Users\\Dell\\Desktop\\PraticaP\\\\scripts\\arquivo.txt\"\n",
    "corpus = PlaintextCorpusReader(dir, '.*', encoding=\"utf-8\")\n",
    "corpus.fileids()\n",
    "texto_corpus = corpus.raw(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1537f63-b329-45ab-9c33-4be439abcd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria nuvem de palavras\n",
    "stops = stopwords.words('english')\n",
    "mapa_cores = ListedColormap(['orange', 'green', 'red', 'magenta'])\n",
    "nuvem = WordCloud(background_color='white',\n",
    "                  colormap=mapa_cores,\n",
    "                  stopwords=stops,\n",
    "                  max_words=100)\n",
    "nuvem.generate(texto)\n",
    "plt.imshow(nuvem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554bb21-ed60-484e-b519-283d0efc48c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
